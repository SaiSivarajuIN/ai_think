# Release Notes: v0.0.1-beta

This is the **first beta release** of **AI Think | Ollama Chat**, a self-hosted, web-based interface for interacting with local Ollama models.

It lays the foundation for the application with a clean chat UI, dynamic model controls, system monitoring, and observability features.

As an early beta release, it‚Äôs intended for **testing, exploration, and feedback**.

---

## ‚ú® Key Features

* **Core Chat Interface** ‚Äì A clean, responsive UI for chatting with any model served by your local Ollama instance.
* **Dynamic Model Selection** ‚Äì Switch between available Ollama models on the fly directly from the chat interface.
* **Persistent Chat History**

  * Conversations are automatically saved.
  * Review and manage past chats on the `/history` page.
  * Delete individual messages when needed.
  * Threads are smartly sorted by recent activity.
* **Flexible Data Storage**

  * **SQLite**: Default local storage via `chat.db` for easy setup.
  * **ChromaDB** (optional): Cloud integration for scalable and persistent vector storage, with automatic fallback to SQLite.
* **System Health Dashboard (`/health`)** ‚Äì Real-time monitoring of:

  * CPU, Memory, and Disk usage
  * GPU stats (if available)
  * Service connections (Ollama, Langfuse, ChromaDB)
* **Runtime Configuration (`/settings`)**

  * Adjust model parameters (e.g., `temperature`, `top_k`, `num_predict`) dynamically.
  * Configure integration credentials without restarting the server.
* **Observability with Langfuse** (optional)

  * Tracing for LLM interactions.
  * Monitor prompts, responses, latency, token usage, and costs.
* **Robust Backend**

  * **API Resilience**: Automatic retries with exponential backoff for Ollama API calls.
  * **Advanced Logging**: Daily rotating log files saved in `logger/` for easier debugging.

---

## üìù Known Issues & Future Work

* UI polish and design refinements planned.
* Response regeneration works only for the latest message.
* Backend error messages need more user-friendly presentation.
---


# Release Notes: v0.0.1-beta.2

This release introduces the **Ollama Models Hub**, a significant new feature allowing users to manage local models directly from the web interface. It also includes important fixes and improvements.

---

#### ‚ú® New Features

*   **Ollama Models Hub (`/models`)**
    *   A new page has been added to view, pull, and delete local Ollama models without needing to use the command line.
    *   **View Local Models:** See a list of all downloaded models, their size, and when they were last modified.
    *   **Pull New Models:** Enter a model name (e.g., `llama3:8b`) to download it from the Ollama library. The UI provides real-time streaming feedback and a progress bar during the download.
    *   **Delete Models:** Easily remove models you no longer need to free up disk space.
    *   Backend support was added with new API endpoints (`/api/models`, `/api/models/pull`, `/api/models/delete`) to interact with the Ollama service.

#### üêõ Bug Fixes

*   **Corrected GGUF Model Path:** The `install.sh` script was updated to use the correct Hugging Face model path (`unsloth/gpt-oss-7b-gguf:q4_k_m`), resolving a "model not found" error during setup.
*   **Model Deletion API:** The `/api/models/delete` endpoint in `app.py` was improved to correctly handle empty responses from the Ollama API upon successful deletion, preventing a potential frontend error.

#### ‚öôÔ∏è Improvements

*   **Simplified Feature Request Template:** The GitHub issue template for feature requests (`20_feature_request.yml`) has been streamlined to make it quicker and easier for users to submit new ideas.

---

#### üìù Known Issues & Future Work
* Response regeneration works only for the latest message.

* UI polish and design refinements planned.
* Response regeneration works only for the latest message.
* Backend error messages need more user-friendly presentation.

---

üí° **We welcome feedback and bug reports**

**Full issues**: https://github.com/SaiSivarajuIN/ai_think/issues


# Release Notes: v0.0.1-beta.3

This release introduces significant enhancements focused on configuration, observability, and user experience. Key additions include a new settings page for dynamic model parameter adjustment, robust Langfuse integration for tracing, a system health dashboard, and a models hub for managing local Ollama models.

---

### ‚ú® New Features

*   **File Upload for Contextual Chat**:
    *   Users can now upload `.txt` files directly in the chat interface.
    *   The application uses the file's content as context, allowing users to ask questions about the document.
*   **Models Hub (`/models`)**:
    *   A new UI to view, pull, and delete local Ollama models directly from the application.
    *   Provides real-time progress for model downloads.
*   **Dynamic Settings Page (`/settings`)**:
    *   Users can now configure model parameters (`temperature`, `top_p`, `top_k`, etc.) and manage Langfuse credentials without restarting the server.
*   **System Health Dashboard (`/health`)**:
    *   A dedicated page to monitor real-time system metrics, including CPU, memory, disk, and GPU usage.
    *   Displays the connection status of Ollama, Langfuse, and ChromaDB.
*   **Langfuse Integration**:
    *   Added optional integration with Langfuse for detailed tracing and observability of LLM interactions.
*   **ChromaDB Integration**:
    *   Support for ChromaDB as a scalable, persistent backend for chat history, with a graceful fallback to SQLite.

### ‚öôÔ∏è Improvements & Fixes

*   **Enhanced History Page**:
    *   Threads are now correctly sorted by the most recent message.
    *   Users can delete individual messages or entire conversation threads.
*   **Improved Stability**:
    *   Implemented an API retry mechanism with exponential backoff for calls to the Ollama service.
    *   Increased the API timeout to 5 minutes to support slower models.
*   **Advanced Logging**:
    *   Upgraded to a `TimedRotatingFileHandler` for daily log rotation, storing logs for up to 30 days for easier debugging.
*   **UI/UX**:
    *   Fixed an issue where deleting a model could cause a frontend error due to an empty API response.
    *   Timestamps are now consistently handled and displayed in the user's local time zone.

---

#### üìù Known Issues & Future Work
* Response regeneration works only for the latest message.

* UI polish and design refinements planned.
* Response regeneration works only for the latest message.
* Backend error messages need more user-friendly presentation.

---

üí° **We welcome feedback and bug reports**

**Full issues**: https://github.com/SaiSivarajuIN/ai_think/issues

**Full Changelog**: https://github.com/SaiSivarajuIN/ai_think/compare/v0.0.1-beta.2...v0.0.1-beta.3


# Release Notes: v0.0.1-beta.4

This release introduces major new functionality, including web search capabilities via SearXNG and a more robust file upload system that now supports PDFs. It also includes several backend improvements for a more stable and intuitive user experience.

---

### ‚ú® New Features

*   **Web Search with SearXNG**:
    *   The application can now connect to a self-hosted [SearXNG](https://github.com/searxng/searxng) instance to perform live web searches.
    *   Users can trigger a search from the chat input by typing `/search <your query>`.
    *   The search results are automatically provided as context to the LLM, enabling it to answer questions with up-to-date information.
    *   SearXNG can be enabled and configured from the `/settings` page.

---

#### üìù Known Issues & Future Work
*   Response regeneration is still limited to the most recent message in the conversation.
*   UI/UX refinements are ongoing.


# Release Notes: v0.0.1-beta.5

This release introduces the **Prompt Hub**, a major new feature for creating, managing, and reusing prompts directly within the application. It also includes several important documentation updates and backend improvements to enhance usability and maintainability.

---

### ‚ú® New Features

*   **Prompt Hub (`/prompts`)**
    *   A new page has been added to create, view, edit, and delete reusable prompts.
    *   **Create & Manage Prompts:** A user-friendly modal allows for the creation and editing of prompts with a title, type (e.g., "Code," "Creative"), and content.
    *   **Use Prompts in Chat:** On the main chat page, a new "Select a Prompt" dropdown lets users instantly load a saved prompt's content as a system message for the current conversation, streamlining repetitive tasks.
    *   Backend support was added with new API endpoints (`/api/prompts`, `/api/prompts/create`, `/api/prompts/update/<id>`, `/api/prompts/delete/<id>`) to manage prompts in the SQLite database.
    *   **Web Search with SearXNG**: Trigger a search from the chat input by clicking the üîç icon or typing `/search <your query>` (e.g., `/search latest AI news`).
### ‚öôÔ∏è Improvements & Fixes

*   **File Upload Logic**:
    *   The file upload mechanism in `app.py` has been refactored. It now correctly saves the file content as a "system" message to the active database (SQLite or ChromaDB) before the user sends their first message, ensuring the context is available for the entire conversation.
    *   The logic for prepending file context to the user's prompt has been made more robust.
*   **Documentation Overhaul**:
    *   The `readme.md` and `documentation.md` files have been updated to reflect the latest features, including the new Prompt Hub and improved file upload functionality.
    *   Installation and setup instructions have been clarified.
*   **Code Cleanup**:
    *   Removed the unused `ThreadManager` class, as session management is now handled by the Flask session, simplifying the codebase.
    *   The `system_prompt` column has been removed from the `settings` table schema in `app.py` as it is now managed via the Prompt Hub.

---

#### üìù Known Issues & Future Work

*   Response regeneration is still limited to the most recent message in the conversation.
*   UI/UX refinements for the new Prompt Hub are ongoing.


# Release Notes: v0.0.1-beta.5-fixes

---

### refactor:
   - update text alignment and font size in PDF export; 
   - enhance search result handling in chat history


# Release Notes: v0.0.1-beta.5-fixes.2

---

### Fixes:
   - Refactor environment variables and update Langfuse host configuration


# Release Notes: v0.0.1-beta.5-fixes.3

---

### Fixes:
   - Add understanding parameters page and update settings for Top K


# Release Notes: v0.0.1-beta.5-fixes.4

---

### Fixes:
   - Remove unused route and update logging messages; enhance settings page with model parameters notes


# Release Notes: v0.0.1-beta.6

---

### New Features & Fixes:
   - Implement delete all models API and UI functionality; update setup scripts for Windows and Linux


# Release Notes: v0.0.1-beta.7

---

### New Features & Fixes:
   - Add 'Delete All Threads' functionality to clear chat history


# Release Notes: v0.0.1-beta.8

This release introduces a major new feature‚Äî**Cloud Model Integration**‚Äîallowing you to connect to external model providers. It also includes several important fixes and improvements to enhance stability and user experience.

---

### ‚ú® New Features

* **Cloud Model Integration (`/cloud_models`)**

  * You can now connect to and interact with models from external providers like **OpenAI**, **Perplexity**, **DeepSeek**, **Google Gemini**, and **OpenRouter**.
  * **New Management Page:** A dedicated `/cloud_models` page allows users to add, view, edit, and delete external model configurations.
  * **Seamless Integration:** Once configured, cloud models are automatically added to the model selection dropdown on the main chat page, prefixed with `cloud::`, making switching between local and cloud models easy.
  * **Secure API Key Handling:** API keys are securely stored in the database and never fully exposed on the frontend.
  * **Flexible Configuration:** Includes a generic "Other" option for connecting to any OpenAI-compatible API endpoint.

---

### ‚öôÔ∏è Improvements & Fixes

* **API Endpoint Documentation**

  * The `documentation.md` file has been updated with detailed information on the new Cloud Model CRUD endpoints to ensure complete and accurate developer guidance.

---

### üìù Known Issues & Future Work

* Token usage display and billing info for cloud providers are not yet implemented.
* Auto-reconnect or error handling for rate-limited or expired API keys is planned for a future release.
* UI/UX polish for the cloud model management page is ongoing.


# Release Notes: v0.0.1-beta.9

This release expands on the **Cloud Model Integration** feature with a more robust model management system, improved UI/UX, and key backend fixes to enhance compatibility, stability, and usability.

---

### ‚ú® New Features

* **Cloud Model Management Enhancements (continue from v8)**

  * The `/cloud_models` page has been significantly improved, now featuring modals for adding and editing external model configurations.
  * Supports major providers like **OpenAI**, **DeepSeek**, **Perplexity**, and others.
  * Cloud models continue to be automatically listed in the model selector on the main chat page, prefixed with `cloud::`.

* **Enhanced Settings Page**

  * The settings page (`settings.html`) has been redesigned for improved clarity and user guidance.
  * A new **"Model Parameters Notes"** section explains key concepts like Tokens, Temperature, Top-K, and Top-P.
  * Layout improvements using a grid system provide better organization of configuration options.
  * 
* **Sidebar Navigation**

  * Replaced the top navbar with a **collapsible sidebar** for improved navigation.
  * Sidebar now includes a **toggle button** to expand or collapse the menu.

* **API Key Copy Function**

  * Added a **copy-to-clipboard** button next to API key fields for quick and easy copying.

---

### ‚öôÔ∏è Improvements & Fixes

* **API Compatibility**

  * Updated the `cloud_model_chat` function in `app.py` to properly construct API URLs, ensuring compatibility with OpenAI-style APIs.
  * Includes a safeguard to prevent duplicate `/chat/completions` paths in custom base URLs.

* **File Upload Support for Cloud Models**

  * Fixed an issue where uploaded files (via `upload_file`) were not correctly handled when chatting with cloud models.
  * Now cloud-based chats can process and reference uploaded files as expected.

* **UI/UX Enhancements**

  * The cloud models page now uses consistent UI elements (e.g. modals) similar to other pages like **Prompt Hub** and **Local Models**.
  * Notes and links on the settings page are now more readable and user-friendly.

* **Backend Stability**

  * Refactored logic in `app.py` to improve error handling and API call reliability for cloud models.

---

### üêõ Bug Fixes

* **Cloud Model Management Enhancements (continue from v8)**

  * The `/cloud_models` page has been significantly improved, now featuring modals for adding and editing external model configurations.
  * Supports major providers like **OpenAI**, **DeepSeek**, **Perplexity**, and others.
  * Cloud models continue to be automatically listed in the model selector on the main chat page, prefixed with `cloud::`.

* **Cloud Model API Requests**

  * Fixed a critical issue where API requests to cloud providers were failing due to incorrect URL construction.
  * Logic now ensures the `/chat/completions` path is appended correctly, avoiding duplicate or malformed endpoints.

---

### üîÆ Known Issues & Future Plans

* Display of token usage and billing data for cloud models is not yet implemented.
* Auto-reconnect and enhanced error handling for expired or rate-limited API keys is planned for a future update.
* Ongoing UI/UX improvements for the `/cloud_models` management interface.


### Release Notes: v0.0.1-beta.10

This release focuses on improving user experience and state management. Key features include a new history sidebar for quick navigation, session management via URL parameters, and the ability to toggle the visibility of models in the chat interface.


#### ‚ú® Features

*   **History Sidebar**: A new collapsible sidebar has been added to the main chat page. It displays a list of recent chat sessions, allowing users to quickly switch between conversations.
*   **Session Management in URL**: Chat sessions are now managed via a `session_id` in the URL (e.g., `/?session_id=...`). This allows for bookmarking, sharing, and resuming specific conversations.
*   **Model Activity Toggle**: Both local Ollama models and configured cloud models can now be individually enabled or disabled from the UI (`/models` and `/cloud_models` pages) without being deleted. This provides better control over which models appear in the selection dropdown on the chat page.
*   **Local Model Database Persistence**: A new `local_models` table has been added to the database to persist the active/inactive state of local Ollama models across application restarts.


#### üêõ Fixes

*   **UI Cleanup**: Removed extra white spaces on the `/prompts` page for a cleaner and more consistent layout.


# Release Notes: v0.0.1-beta.10

This release focuses on improving user experience and state management. Key features include a new history sidebar for quick navigation, session management via URL parameters, and the ability to toggle the visibility of models in the chat interface.


#### ‚ú® Features

*   **History Sidebar**: A new collapsible sidebar has been added to the main chat page. It displays a list of recent chat sessions, allowing users to quickly switch between conversations.
*   **Session Management in URL**: Chat sessions are now managed via a `session_id` in the URL (e.g., `/?session_id=...`). This allows for bookmarking, sharing, and resuming specific conversations.
*   **Model Activity Toggle**: Both local Ollama models and configured cloud models can now be individually enabled or disabled from the UI (`/models` and `/cloud_models` pages) without being deleted. This provides better control over which models appear in the selection dropdown on the chat page.
*   **Local Model Database Persistence**: A new `local_models` table has been added to the database to persist the active/inactive state of local Ollama models across application restarts.


#### üêõ Fixes

*   **UI Cleanup**: Removed extra white spaces on the `/prompts` page for a cleaner and more consistent layout.

# Release Notes: v0.0.1-beta.11

This release focuses on improving user experience and control with new features around search functionality, response handling, and model management.

---

### ‚ú® New Features

* **Dynamic Web Search Button**
  * The 'Web Search' button in the main chat interface is now automatically disabled when SearXNG is disabled in the Settings page
  * This provides clearer visual feedback about available features based on configuration

* **Response Interruption**
  * The 'Send' button now transforms into a 'Stop' button while the bot is generating a response
  * Users can click the 'Stop' button to immediately halt the bot's response generation
  * When generation is stopped:
    * The partial bot response is cleared from the UI
    * Neither the user's message nor the bot's partial response are saved to history
    * No entries are created in the database history table
    

* **Dynamic Active Model Display**
  * The 'Active Model' field in the Health dashboard now dynamically reflects the currently selected model from the model-selector dropdown in the main chat interface
  * This ensures real-time accuracy of system status information

---

### üìù Known Issues & Future Work

* Response regeneration is still limited to the most recent message in the conversation
* UI/UX refinements are ongoing
* Token usage display and billing info for cloud providers are not yet implemented
* Langfuse tracing is properly terminated without storing interrupted responses `(not fixed)`
