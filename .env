# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3:latest

# Langfuse Host
LANGFUSE_HOST=https://us.cloud.langfuse.com

# Default settings
NUM_PREDICT=2024
TEMPERATURE=0.7
TOP_P=0.8
TOP_K=20
system_prompt=You are a helpful assistant. Always avoid causing harm to the user. Provide clear, step‑by‑step guidance and useful information.


SEARXNG_URL=http://localhost:8080  # your SearXNG instance
