# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:1b

# Langfuse Host
LANGFUSE_HOST=https://us.cloud.langfuse.com

# Default settings
NUM_PREDICT=3024
TEMPERATURE=0.7
TOP_P=0.9
TOP_K=50
OLLAMA_SYSTEM_PROMPT=You are a helpful assistant. Always avoid causing harm to the user. Provide clear, step‑by‑step guidance and useful information.

# SearXNG Configuration
SEARXNG_URL=//localhost:8080  
